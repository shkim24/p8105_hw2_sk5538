HW2
================
Senna
2024-09-30

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

## Problem 1

read and clean data

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

    ## # A tibble: 6 × 10
    ##   line   station_name station_latitude station_longitude route_index route entry
    ##   <chr>  <chr>                   <dbl>             <dbl> <chr>       <chr> <lgl>
    ## 1 4 Ave… 25th St                  40.7             -74.0 1           R     TRUE 
    ## 2 4 Ave… 36th St                  40.7             -74.0 1           N     TRUE 
    ## 3 4 Ave… 36th St                  40.7             -74.0 2           R     TRUE 
    ## 4 4 Ave… 45th St                  40.6             -74.0 1           R     TRUE 
    ## 5 4 Ave… 53rd St                  40.6             -74.0 1           R     TRUE 
    ## 6 4 Ave… 53rd St                  40.6             -74.0 1           R     FALSE
    ## # ℹ 3 more variables: vending <chr>, entrance_type <chr>, ada <lgl>

First, the raw dataset has its name cleaned and the ‘entry’ variable is
turned into a logical variable.

The dataset is not tidy as it has information on routes spread across 11
columns. This is because the stations serve different numbers of routes
ranging from 1 to 11. So, the 11 columns were combined into route and
route index for each station, dropping any rows with NA in the route
column (e.g. Now, if a station serves 2 routes, the route index would
number the two routes 1 and 2 respectively). Relevant variables are
retained with no duplicates. The dataset is now tidy.

It contains relevant variables of line, station_name, station_latitude,
station_longitude, route_index, route, entry, vending, entrance_type,
ada, and the dimensions are 1559, 10

How many distinct stations are there? Note that stations are identified
both by name and by line (e.g. 125th St 8th Avenue; 125st Broadway;
125st Lenox); the distinct function may be useful here.

``` r
distinct_station = distinct(mta_df, line, station_name)
nrow(distinct_station)
```

    ## [1] 465

How many stations are ADA compliant?

``` r
ada_stations = mta_df |>
  filter(ada == TRUE) |>
  distinct (station_name, line)

nrow(ada_stations)
```

    ## [1] 84

What proportion of station entrances / exits without vending allow
entrance?

``` r
no_vending_entrances <- mta_df |>
  filter(vending == "NO") |>
  summarise(proportion = mean(entry))
no_vending_entrances
```

    ## # A tibble: 1 × 1
    ##   proportion
    ##        <dbl>
    ## 1      0.321

Reformat data so that route number and route name are distinct
variables.

``` r
mta_new <- mta_df |>
  mutate(
    route_name = ifelse(is.na(as.numeric(route)), route, NA),
    route_number = ifelse(!is.na(as.numeric(route)), as.numeric(route), NA)
  )|>
  select(
    line, station_name, route_index, route_name, route_number, everything()
  )
```

    ## Warning: There were 3 warnings in `mutate()`.
    ## The first warning was:
    ## ℹ In argument: `route_name = ifelse(is.na(as.numeric(route)), route, NA)`.
    ## Caused by warning in `ifelse()`:
    ## ! NAs introduced by coercion
    ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 2 remaining warnings.

``` r
view(mta_new)
```

How many distinct stations serve the A train? Of the stations that serve
the A train, how many are ADA compliant?

``` r
A_train = mta_new |>
  filter (route_name =="A")
nrow(distinct(A_train, station_name, line))

ada_A_train = A_train|>
  filter(ada == TRUE)
nrow(distinct(ada_A_train, station_name, line))
```

## Problem 2

specify the sheet in the Excel file and to omit non-data entries (rows
with notes / figures; columns containing notes) using arguments in
read_excel use reasonable variable names

``` r
mr_trashwheel= read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
                          sheet=1, 
                          skip=1, 
                          na = c(".", "NA", ""),
                          )|>
  janitor::clean_names()|>
  select(-x15,-x16)
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

omit rows that do not include dumpster-specific data round the number of
sports balls to the nearest integer and converts the result to an
integer variable (using as.integer)

``` r
mr_trashwheel = mr_trashwheel|>
  drop_na(dumpster)|>
  mutate (sports_balls = as.integer(round(sports_balls)))
```

Use a similar process to import, clean, and organize the data for
Professor Trash Wheel and Gwynnda, and combine this with the Mr. Trash
Wheel dataset to produce a single tidy dataset. To keep track of which
Trash Wheel is which, you may need to add an additional variable to both
datasets before combining.

``` r
professor_trashwheel= read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
                          sheet=2, 
                          skip=1, 
                          na = c(".", "NA", ""),
                          )|>
  janitor::clean_names()|>
  mutate(trashwheel = "professor trashwheel")|>
  drop_na(dumpster)


gwynnda= read_excel("./data/202309 Trash Wheel Collection Data.xlsx",
                          sheet=4, 
                          skip=1, 
                          na = c(".", "NA", ""),
                          )|>
  janitor::clean_names()|>
  mutate(trashwheel = "gwynnda trashwheel")|>
  drop_na(dumpster)

mr_trashwheel = mr_trashwheel|>
  mutate(year = as.numeric(year),
         trashwheel = "mr trashwheel")
```

``` r
trashwheel_df <- bind_rows(
  mr_trashwheel,
  professor_trashwheel,
  gwynnda
)
```

Write a paragraph about these data; you are encouraged to use inline R.
Be sure to note the number of observations in the resulting dataset, and
give examples of key variables. For available data, what was the total
weight of trash collected by Professor Trash Wheel? What was the total
number of cigarette butts collected by Gwynnda in June of 2022?

``` r
weight_professor = trashwheel_df|>
  filter(trashwheel == 'professor trashwheel')|>
  summarize (total_weight = sum(weight_tons))

weight_professor
```

    ## # A tibble: 1 × 1
    ##   total_weight
    ##          <dbl>
    ## 1         216.

``` r
cigarette_gwynnda = trashwheel_df|>
  filter(trashwheel == 'gwynnda trashwheel')|>
  summarize(cigarette = sum(cigarette_butts))

cigarette_gwynnda
```

    ## # A tibble: 1 × 1
    ##   cigarette
    ##       <dbl>
    ## 1    367010

## Problem 3

your goal is to create a single, well-organized dataset with all the
information contained in these data files. To that end: import, clean,
tidy, and otherwise wrangle each of these datasets;

``` r
bakers = read_csv(file = './data/gbb_datasets/bakers.csv') |>
  janitor::clean_names()
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes = read_csv(file = './data/gbb_datasets/bakes.csv', na = "N/A")|>
  janitor::clean_names()
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results = read_csv(file = './data/gbb_datasets/results.csv', skip=2)|>
  janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

check for completeness and correctness across datasets (e.g. by viewing
individual datasets and using anti_join);

``` r
# extract first name from bakers

bakers = bakers|>
  mutate(baker = word(baker_name,1))|>
  select(series, baker, everything())


bakes_results = bakes|>
  full_join (results, by = c('baker','series','episode'))

full_df = bakers|>
  full_join(bakes_results, by = c('baker','series'))|>
  select(baker_name, series, episode, result, technical, signature_bake, show_stopper, everything(), -baker)|>
  drop_na(result)
```

Export the result as a CSV in the directory containing the original
datasets.

``` r
write.csv(full_df, "./data/gbb_datasets/great_british_bake_off.csv", row.names = FALSE)
```
